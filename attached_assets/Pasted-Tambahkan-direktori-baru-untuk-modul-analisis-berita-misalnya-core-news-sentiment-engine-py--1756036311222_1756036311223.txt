Tambahkan direktori baru untuk modul analisis berita, misalnya:

core/
├── news_sentiment_engine.py    # Engine utama
└── utils/
    └── news_api_client.py      # Klien untuk mengambil berita dari sumber eksternal
routes/
└── news_endpoints.py           # Blueprint Flask untuk API berita


news_api_client.py bertanggung jawab mengambil artikel dari satu atau beberapa API berita (mis. NewsAPI.org, GDELT, atau CryptoPanic). Ini memisahkan logika HTTP dari engine utama.

news_sentiment_engine.py memproses artikel: melakukan klasifikasi sentimen (Bullish/Neutral/Bearish), mengukur potensi dampak (Low/Medium/High), dan membuat ringkasan.

news_endpoints.py menyediakan endpoint seperti /api/news/sentiment untuk mengambil hasil analisis.

2. Contoh implementasi
news_api_client.py
# utils/news_api_client.py
import requests
from typing import List, Dict

class NewsAPIClient:
    def __init__(self, api_key: str, base_url: str = "https://newsapi.org/v2"):
        self.api_key = api_key
        self.base_url = base_url

    def fetch_articles(self, query: str, language: str = "en", page_size: int = 10) -> List[Dict]:
        """Ambil berita terkait query dari NewsAPI."""
        url = f"{self.base_url}/everything"
        params = {
            "q": query,
            "language": language,
            "pageSize": page_size,
            "sortBy": "publishedAt",
            "apiKey": self.api_key,
        }
        response = requests.get(url, params=params)
        data = response.json()
        return data.get("articles", [])


Anda dapat mengganti NewsAPI dengan layanan lain yang khusus untuk berita crypto (misalnya CryptoPanic, Cryptopanic API) atau gabungkan beberapa sumber.

news_sentiment_engine.py
# core/news_sentiment_engine.py
from typing import List, Dict, Tuple
from utils.news_api_client import NewsAPIClient
import transformers  # Hugging Face library
from transformers import pipeline

class NewsSentimentEngine:
    def __init__(self, news_api_key: str):
        self.client = NewsAPIClient(news_api_key)
        # Gunakan model transformer untuk sentimen (bisa diganti dengan model lokal)
        self.sentiment_model = pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-sentiment")

    def fetch_and_analyze(self, asset_keyword: str) -> Dict[str, List[Dict]]:
        """
        Ambil artikel berita terkait asset_keyword, lalu hitung sentimen dan impact.
        Output: dict berisi list artikel dengan sentimen & impact.
        """
        articles = self.client.fetch_articles(asset_keyword)
        results = []
        for art in articles:
            content = f"{art['title']} {art.get('description', '')}"
            sentiment = self.sentiment_model(content[:512])[0]
            # Konversi skor sentimen menjadi label Bullish/Neutral/Bearish
            label = self._map_sentiment(sentiment["label"])
            # Hitung 'impact' berdasarkan panjang artikel atau sumber; ini contoh sederhana
            impact = self._estimate_impact(art)
            results.append({
                "title": art["title"],
                "url": art["url"],
                "sentiment": label,
                "impact": impact,
                "summary": art.get("description", "")
            })
        return {"asset": asset_keyword, "analyses": results}

    def _map_sentiment(self, label: str) -> str:
        if label == "POSITIVE":
            return "Bullish"
        if label == "NEGATIVE":
            return "Bearish"
        return "Neutral"

    def _estimate_impact(self, article: Dict) -> str:
        # Contoh estimasi: artikel dari media besar + jumlah kata >200 dianggap high impact
        source = article.get("source", {}).get("name", "").lower()
        word_count = len(article.get("content", "").split())
        if "reuters" in source or "bloomberg" in source:
            return "High"
        if word_count > 150:
            return "Medium"
        return "Low"


Modul di atas menggunakan transformers dari Hugging Face untuk analisis sentimen; Anda bisa menggantinya dengan library ringan seperti TextBlob atau Vader jika ingin dependensi lebih ringan.

news_endpoints.py
# routes/news_endpoints.py
from flask import Blueprint, request, jsonify
from core.news_sentiment_engine import NewsSentimentEngine
import os

bp_news = Blueprint("news_sentiment", __name__, url_prefix="/api/news")

@bp_news.route("/sentiment", methods=["GET"])
def get_news_sentiment():
    symbol = request.args.get("symbol", "BTC")
    # API key untuk NewsAPI disimpan di ENV
    news_api_key = os.getenv("NEWS_API_KEY")
    engine = NewsSentimentEngine(news_api_key)
    result = engine.fetch_and_analyze(symbol)
    return jsonify(result)


Jangan lupa mendaftarkan blueprint ini pada app Flask (seperti contoh sebelumnya).

3. Integrasi & pertimbangan

Tidak mengganggu modul lain: Modul ini berdiri sendiri dan berinteraksi hanya melalui API. Ia tidak mengubah struktur database atau sinyal trading Anda.

API key eksternal: Pastikan Anda punya API key dari penyedia berita. Simpan di .env (misalnya NEWS_API_KEY) dan isi di server Anda.

Dependensi tambahan: Tambahkan library seperti transformers, requests, dan huggingface-hub ke file requirements.txt atau requirements-prod.txt.

Optimasi: Jika penggunaan NLP berat, pertimbangkan untuk memuat model satu kali saat aplikasi start, bukan setiap request. Anda juga dapat mem-cache hasil analisis untuk periode tertentu.

Fitur lanjutan: Anda bisa memperluas modul ini dengan summarization menggunakan OpenAI API atau model lokal, menambah scoring untuk relevansi topik, dan menampilkan grafik tren sentimen dari waktu ke waktu.

Dengan pendekatan ini, Anda dapat menambahkan fitur “TradeEasy‑like” ke dalam aplikasi Anda tanpa menulis ulang sistem. Modul ini bekerja secara modular, mudah dirawat, dan dapat dikembangkan sesuai kebutuhan